{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687c010-7590-4435-9622-90504382b8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import glob\n",
    "import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import yaml\n",
    "import argparse\n",
    "\n",
    "# PyTorch Modules\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "class BiGRUver2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(BiGRUver2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.linear1 = nn.Linear(input_size, input_size)\n",
    "        self.linear2 = nn.Linear(input_size, input_size)\n",
    "\n",
    "        self.GRU = nn.GRU(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.linear3 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).cuda()\n",
    "        # c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        out, h_n = self.GRU(x, h0)\n",
    "        h_n = h_n.transpose(0,1)\n",
    "        h_n = torch.flatten(h_n, start_dim=1, end_dim=-1)\n",
    "        studyLevelOutputs = F.relu(self.linear3(h_n))\n",
    "        studyLevelOutputs = self.linear4(studyLevelOutputs)\n",
    "\n",
    "        return studyLevelOutputs\n",
    "\n",
    "class simpleANN(nn.Module):\n",
    "    def __init__(self, sequence_size, input_size):\n",
    "        super(simpleANN, self).__init__()\n",
    "        self.linear1 = nn.Linear(sequence_size*input_size, 312)\n",
    "        self.linear2 = nn.Linear(312, 156)\n",
    "        self.linear3 = nn.Linear(156, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "\n",
    "        # Forward pass\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class labCollabLM(pl.LightningModule):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(params)\n",
    "        self.mainModel = BiGRUver2(input_size=52, hidden_size=32, num_layers=self.hparams.num_layers)\n",
    "        #self.mainModel = simpleANN(sequence_size=12, input_size=52)\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        #self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "        # Metrics\n",
    "        self.accuracy = torchmetrics.Accuracy(task='binary')\n",
    "        self.AUROC = torchmetrics.classification.BinaryAUROC()\n",
    "        self.learning_rate = self.hparams.lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_class = self.mainModel(x)\n",
    "        return z_class\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _, _ = batch\n",
    "        z_class = self.mainModel(x)\n",
    "        y_class = torch.sigmoid(z_class)\n",
    "\n",
    "        # class loss\n",
    "        totalLoss = self.criterion(z_class, y)\n",
    "\n",
    "        self.log('train_totalLoss', totalLoss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return totalLoss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, mrn, frame = batch\n",
    "        z_class = self.mainModel(x)\n",
    "        y_class = torch.sigmoid(z_class)\n",
    "\n",
    "        #print(y_class.dtype)\n",
    "        #print(y.dtype)\n",
    "        #breakpoint()\n",
    "\n",
    "        '''\n",
    "        if torch.sum(y)==0 or torch.sum(y)==self.hparams.batch_size:\n",
    "            totalLoss = 0\n",
    "            self.log('error', 1, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True, batch_size=self.hparams.batch_size)\n",
    "        else:\n",
    "            totalLoss = self.criterion(z_class, y)\n",
    "            self.log('error', 0, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True, batch_size=self.hparams.batch_size)\n",
    "        '''\n",
    "\n",
    "        totalLoss = self.criterion(z_class, y)\n",
    "        self.log('valid_totalLoss', totalLoss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "\n",
    "        # Additional classification metrics\n",
    "        #y_class = torch.sigmoid(z_class)\n",
    "\n",
    "        class_score = y_class\n",
    "        class_true = y.type(torch.int32)\n",
    "\n",
    "        return {\n",
    "            'class_score' : class_score,\n",
    "            'class_true' : class_true,\n",
    "            'mrn' : mrn,\n",
    "            'frame' : frame\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        y_score = torch.cat([eachBatchOutput['class_score'] for eachBatchOutput in outputs])\n",
    "        y_true = torch.cat([eachBatchOutput['class_true'] for eachBatchOutput in outputs])\n",
    "        mrn = torch.cat([eachBatchOutput['mrn'] for eachBatchOutput in outputs])\n",
    "        frame = torch.cat([eachBatchOutput['frame'] for eachBatchOutput in outputs])\n",
    "\n",
    "        acc_score = self.accuracy(y_score, y_true)\n",
    "        AUROC_score = self.AUROC(y_score, y_true)\n",
    "        self.log('valid_class_accuracy', acc_score, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('valid_class_AUROC', AUROC_score, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.saveScores(y_score, y_true, mrn, frame)\n",
    "        \n",
    "        # Calculate true positives, true negatives, false positives, and false negatives\n",
    "        true_positives = torch.sum((y_score >= 0.5) & (y_true == 1))\n",
    "        true_negatives = torch.sum((y_score < 0.5) & (y_true == 0))\n",
    "        false_positives = torch.sum((y_score >= 0.5) & (y_true == 0))\n",
    "        false_negatives = torch.sum((y_score < 0.5) & (y_true == 1))\n",
    "\n",
    "        # Calculate sensitivity and specificity\n",
    "        sensitivity = true_positives / (true_positives + false_negatives)\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "        # Log and print the results\n",
    "        self.log('valid_sensitivity', sensitivity, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('valid_specificity', specificity, prog_bar=True, logger=True, sync_dist=True)\n",
    "        print(\"Sensitivity (Sen):\", sensitivity)\n",
    "        print(\"Specificity (Spec):\", specificity)\n",
    "\n",
    "    return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.mainModel.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def saveScores(self, class_score, class_true, mrn, frame):\n",
    "        class_score = class_score.cpu().detach().numpy().flatten()\n",
    "        class_true = class_true.cpu().detach().numpy().flatten()\n",
    "        mrn = mrn.cpu().detach().numpy().flatten()\n",
    "        frame = frame.cpu().detach().numpy().flatten()\n",
    "\n",
    "        savePath = 'outputs/tempScores/epoch.csv'.replace('epoch', str(self.current_epoch).zfill(3))\n",
    "\n",
    "        scoreDict = {'class_score': class_score, 'class_true': class_true, 'mrn':mrn, 'frame':frame}\n",
    "        scoreDF = pd.DataFrame(scoreDict)\n",
    "        scoreDF.to_csv(savePath)\n",
    "\n",
    "    def comp_loss(self, z_hat, y):\n",
    "        return F.binary_cross_entropy_with_logits(z_hat, y, reduction = 'mean')\n",
    "\n",
    "class labCollabDataset(BaseDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataframe=None,\n",
    "            patientList=None,\n",
    "            args=None\n",
    "    ):\n",
    "        self.dataframe = dataframe\n",
    "        self.patientList = patientList\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        thisPatientMRN = self.patientList[i]\n",
    "        thisSeries = self.dataframe.loc[thisPatientMRN]\n",
    "\n",
    "        if thisSeries.loc['IDA']:\n",
    "            startFrame = int(thisSeries.loc['reelFrame'])-random.randint(18,24)\n",
    "        else:\n",
    "            startFrame = random.randint(thisSeries.loc['startNonZero'],338)\n",
    "\n",
    "        endFrame = startFrame+12\n",
    "\n",
    "        selectedReel = np.zeros((52,12))\n",
    "\n",
    "        patientReel = np.load('Data/lab_data_patientReels/'+str(thisPatientMRN)+'.npy')\n",
    "        patientReel = np.nan_to_num(patientReel)\n",
    "        selectedReel[:,:] = patientReel[:,startFrame:endFrame]\n",
    "        selectedReel=np.transpose(selectedReel).astype(np.float32)\n",
    "        GTlabels = np.array([thisSeries.loc['IDA'].astype(np.float16)]) # pytorch lightning like this as a numpy array, size (batch, 1)\n",
    "\n",
    "        return selectedReel, GTlabels, thisPatientMRN, startFrame\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patientList)\n",
    "\n",
    "class labCollabDM(pl.LightningDataModule):\n",
    "    def __init__(self, args=None):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.dataDF = pd.read_csv('Data/Fe_def_outcome_cleanedAndStratified_YN_230701.csv', index_col='mrn')\n",
    "        self.dataDF = self.dataDF[self.dataDF['blacklist2'] == 'False']\n",
    "\n",
    "        # get train list\n",
    "        trainDF = self.dataDF[self.dataDF['fold'] != self.args.fold]\n",
    "        self.trainList = trainDF.index.to_list()\n",
    "\n",
    "        # get valid list\n",
    "        validDF = self.dataDF[self.dataDF['fold'] == self.args.fold]\n",
    "        self.validList = validDF.index.to_list()\n",
    "\n",
    "        self.trainDataset = labCollabDataset(dataframe=self.dataDF, patientList=self.trainList, args=args)\n",
    "        self.validDataset = labCollabDataset(dataframe=self.dataDF, patientList=self.validList, args=args)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        return\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        trainDataloader = DataLoader(self.trainDataset, batch_size=self.args.batch_size, shuffle=True, num_workers=self.args.num_workers)\n",
    "        return trainDataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        validDataloader = DataLoader(self.validDataset, batch_size=self.args.batch_size, shuffle=False, num_workers=self.args.num_workers)\n",
    "        return validDataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(pl.__version__)\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    # load config file\n",
    "    with open('120_config.yaml') as file:\n",
    "        defaultConfigDict = yaml.safe_load(file)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    for eachKey, eachValue in defaultConfigDict.items():\n",
    "        parser.add_argument('--' + eachKey, default=eachValue, type=type(eachValue))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    # setting up\n",
    "    timeStamp = datetime.now().strftime('%y%m%d%H%M')\n",
    "    runName = timeStamp + '_' + args.tag + '_cv' + str(args.fold)\n",
    "    print(runName)\n",
    "\n",
    "    labCollabLightningModule = labCollabLM(args)\n",
    "    labCollabDataModule = labCollabDM(args=args)\n",
    "\n",
    "    if args.wandb == True:\n",
    "        wandb_logger = WandbLogger(project=args.projectName, name=timeStamp, tags=[args.tag])\n",
    "    else:\n",
    "        wandb_logger = None\n",
    "\n",
    "    '''\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath='checkpoints/' + runName + '/',\n",
    "                                          filename=runName + '-{epoch}-{valid_loss_total:.4f}',\n",
    "                                          monitor='valid_loss_total',\n",
    "                                          save_top_k=100,\n",
    "                                          mode='min')\n",
    "    '''\n",
    "\n",
    "    trainer = pl.Trainer(logger=wandb_logger, log_every_n_steps=10,\n",
    "                         accumulate_grad_batches=10,\n",
    "                         accelerator='gpu', devices=args.num_gpus, strategy='ddp_find_unused_parameters_false', precision = 16,\n",
    "                         #accelerator='ddp', plugins=DDPPlugin(find_unused_parameters=False)],\n",
    "                         max_epochs=args.max_epochs, num_sanity_val_steps=10)\n",
    "    trainer.fit(labCollabLightningModule, labCollabDataModule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (v3.10.2:a58ebcc701, Jan 13 2022, 14:50:16) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
